import os
import tempfile
from typing import List, Dict, Any, Optional, Tuple
import re
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import LLMChain
from langchain.agents import Tool, AgentExecutor, create_openai_tools_agent
from langchain.memory import ConversationBufferMemory
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader
from langchain.schema import Document
import tiktoken
from pinecone import Pinecone, ServerlessSpec

# Importer la configuration
try:
    from config import OPENAI_API_KEY, LLM_MODEL, AGENT_TEMPERATURE, VERBOSE_MODE, PINECONE_API_KEY
except ImportError:
    OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
    LLM_MODEL = os.environ.get("LLM_MODEL", "gpt-3.5-turbo")
    AGENT_TEMPERATURE = float(os.environ.get("AGENT_TEMPERATURE", 0.2))
    VERBOSE_MODE = os.environ.get("VERBOSE_MODE", "True").lower() == "true"
    PINECONE_API_KEY = os.environ.get("PINECONE_API_KEY")

from components import (
    ObjectiveExtractor,
    ContentAnalyzer,
    BloomClassifier,
    ObjectiveFormatter,
    DifficultyEvaluator,
    LearningResourceRecommender,
    FeedbackGenerator
)

class DocumentProcessor:
    """Classe pour traiter et gÃ©rer les documents pÃ©dagogiques avec extraction d'objectifs"""
    
    def __init__(self, embedding_model="text-embedding-3-small", index_name="learn-obj"):
        self.embeddings = OpenAIEmbeddings(
            model=embedding_model,
            openai_api_key=OPENAI_API_KEY
        )
        
        # Initialiser Pinecone
        self._initialize_pinecone(index_name)
        
        # Text splitter optimisÃ© pour les objectifs d'apprentissage
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=400,  # Plus petit pour Ã©viter les erreurs de tokens
            chunk_overlap=80,
            length_function=self._tiktoken_len,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        # LLM pour l'extraction d'objectifs depuis les documents
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.1,
            openai_api_key=OPENAI_API_KEY,
            max_tokens=1000
        )
        
        # Prompt spÃ©cialisÃ© pour l'extraction d'objectifs depuis les documents
        self.objective_extraction_prompt = ChatPromptTemplate.from_messages([
            ("system", """Vous Ãªtes un expert en pÃ©dagogie spÃ©cialisÃ© dans l'identification d'objectifs d'apprentissage dans les documents Ã©ducatifs.

Analysez le texte suivant et identifiez TOUS les objectifs d'apprentissage qu'il contient, qu'ils soient explicites ou implicites.

OBJECTIFS EXPLICITES - Recherchez des formulations comme :
- "Ã€ la fin de ce cours/module, l'Ã©tudiant sera capable de..."
- "Les objectifs de ce cours sont..."
- "L'apprenant devra Ãªtre capable de..."
- "CompÃ©tences visÃ©es :"
- "Learning objectives:"
- "By the end of this course, students will be able to..."

OBJECTIFS IMPLICITES - Identifiez des phrases qui dÃ©crivent clairement ce que l'apprenant doit acquÃ©rir :
- "Ce cours enseigne..." â†’ reformuler en objectif
- "Les Ã©tudiants apprendront..." â†’ reformuler en objectif
- "MaÃ®triser les concepts de..." â†’ reformuler en objectif

FORMAT DE RÃ‰PONSE : Pour chaque objectif trouvÃ©, utilisez ce format exact :
OBJECTIF: [reformulÃ© sous forme "L'apprenant sera capable de..."]
TYPE: [explicite/implicite]
SOURCE: [citation exacte du texte original]
CONTEXTE: [document/section d'oÃ¹ provient l'objectif]

Si aucun objectif n'est trouvÃ©, rÃ©pondez : "AUCUN OBJECTIF IDENTIFIÃ‰"
"""),
            ("human", "TEXTE Ã€ ANALYSER:\n{text}")
        ])
    
    def _initialize_pinecone(self, index_name: str):
        """Initialise la connexion Ã  Pinecone"""
        try:
            pc = Pinecone(api_key=PINECONE_API_KEY)
            
            existing_indexes = pc.list_indexes()
            index_names = [idx.name for idx in existing_indexes]
            
            if index_name not in index_names:
                pc.create_index(
                    name=index_name,
                    dimension=1536,
                    metric='cosine',
                    spec=ServerlessSpec(cloud="aws", region="us-east-1")
                )
            
            self.index = pc.Index(index_name)
            self.index_name = index_name
            print(f"âœ… Pinecone initialisÃ© avec l'index: {index_name}")
            
        except Exception as e:
            print(f"âŒ Erreur lors de l'initialisation de Pinecone: {e}")
            raise
    
    def _tiktoken_len(self, text: str) -> int:
        """Calcule la longueur d'un texte en tokens"""
        try:
            tokenizer = tiktoken.get_encoding("cl100k_base")
            tokens = tokenizer.encode(text, disallowed_special=())
            return len(tokens)
        except Exception:
            # Fallback simple
            return len(text.split())
    
    def extract_text_from_file(self, uploaded_file) -> str:
        """Extrait le texte d'un fichier uploadÃ©"""
        file_extension = uploaded_file.name.split(".")[-1].lower()
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_extension}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        try:
            if file_extension == "pdf":
                loader = PyPDFLoader(tmp_path)
            elif file_extension == "txt":
                loader = TextLoader(tmp_path, encoding='utf-8')
            elif file_extension in ["docx", "doc"]:
                loader = Docx2txtLoader(tmp_path)
            else:
                raise ValueError(f"Type de fichier non supportÃ©: {file_extension}")
            
            docs = loader.load()
            text = "\n".join([doc.page_content for doc in docs])
            
            if not text.strip():
                raise ValueError("Le fichier ne contient pas de texte extractible")
                
            return text
            
        except Exception as e:
            print(f"Erreur lors de l'extraction du fichier {uploaded_file.name}: {e}")
            return f"Erreur d'extraction pour {uploaded_file.name}: {str(e)}"
        finally:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
    
    def process_documents(self, files: List, session_id: str) -> Tuple[List[str], List[str]]:
        """
        Traite une liste de fichiers et les stocke dans Pinecone
        
        Args:
            files: Liste des fichiers uploadÃ©s
            session_id: Identifiant de la session
            
        Returns:
            Tuple contenant les textes extraits et les noms des documents
        """
        document_texts = []
        document_names = []
        vectors_to_upsert = []
        
        for uploaded_file in files:
            try:
                print(f"ğŸ“„ Traitement du fichier: {uploaded_file.name}")
                
                # Extraire le texte
                text = self.extract_text_from_file(uploaded_file)
                
                if "Erreur d'extraction" in text:
                    print(f"âš ï¸ ProblÃ¨me avec {uploaded_file.name}")
                    continue
                
                document_texts.append(text)
                document_names.append(uploaded_file.name)
                
                # Diviser en chunks
                chunks = self.text_splitter.split_text(text)
                print(f"ğŸ“Š {len(chunks)} chunks crÃ©Ã©s pour {uploaded_file.name}")
                
                # CrÃ©er les vecteurs pour Pinecone
                for i, chunk in enumerate(chunks):
                    try:
                        embedding = self.embeddings.embed_query(chunk)
                        
                        vectors_to_upsert.append({
                            "id": f"{session_id}_{uploaded_file.name}_{i}",
                            "values": embedding,
                            "metadata": {
                                "text": chunk,
                                "source": uploaded_file.name,
                                "chunk": i,
                                "session_id": session_id,
                                "content_type": "educational_content",
                                "file_size": len(uploaded_file.getvalue())
                            }
                        })
                    except Exception as chunk_error:
                        print(f"âš ï¸ Erreur chunk {i} de {uploaded_file.name}: {chunk_error}")
                        continue
                        
            except Exception as file_error:
                print(f"âŒ Erreur fichier {uploaded_file.name}: {file_error}")
                continue
        
        # Uploader vers Pinecone par batch
        if vectors_to_upsert:
            batch_size = 50
            total_batches = (len(vectors_to_upsert) + batch_size - 1) // batch_size
            
            for i in range(0, len(vectors_to_upsert), batch_size):
                batch = vectors_to_upsert[i:i + batch_size]
                batch_num = (i // batch_size) + 1
                
                try:
                    self.index.upsert(vectors=batch)
                    print(f"âœ… Batch {batch_num}/{total_batches} uploadÃ© ({len(batch)} vecteurs)")
                except Exception as batch_error:
                    print(f"âŒ Erreur batch {batch_num}: {batch_error}")
                    continue
        
        print(f"ğŸ‰ Traitement terminÃ©: {len(document_texts)} documents, {len(vectors_to_upsert)} chunks")
        return document_texts, document_names
    
    def search_relevant_content(self, query: str, session_id: str, top_k: int = 5) -> List[str]:
        """Recherche du contenu pertinent dans les documents de la session"""
        try:
            query_embedding = self.embeddings.embed_query(query)
            
            results = self.index.query(
                vector=query_embedding,
                top_k=top_k,
                include_metadata=True,
                filter={"session_id": {"$eq": session_id}}
            )
            
            relevant_content = []
            for match in results['matches']:
                content = f"Source: {match['metadata']['source']}\n{match['metadata']['text']}"
                relevant_content.append(content)
            
            return relevant_content
            
        except Exception as e:
            print(f"âŒ Erreur lors de la recherche: {e}")
            return []
    
    def extract_objectives_from_stored_documents(self, session_id: str) -> List[Dict]:
        """
        Extrait les objectifs d'apprentissage de tous les documents stockÃ©s dans Pinecone
        
        Args:
            session_id: ID de la session pour filtrer les documents
            
        Returns:
            Liste des objectifs trouvÃ©s avec leurs mÃ©tadonnÃ©es
        """
        print(f"ğŸ” Recherche d'objectifs dans la session {session_id[:8]}...")
        
        # Mots-clÃ©s pour rechercher les sections contenant des objectifs
        objective_keywords = [
            "objectif apprentissage",
            "learning objective", 
            "compÃ©tence visÃ©e",
            "Ã  la fin de ce cours",
            "l'Ã©tudiant sera capable",
            "students will be able",
            "learning outcome",
            "but pÃ©dagogique",
            "compÃ©tences dÃ©veloppÃ©es",
            "skills acquired"
        ]
        
        all_objectives = []
        processed_chunks = set()  # Pour Ã©viter les doublons
        
        # Rechercher pour chaque mot-clÃ©
        for keyword in objective_keywords:
            try:
                query_embedding = self.embeddings.embed_query(keyword)
                
                results = self.index.query(
                    vector=query_embedding,
                    top_k=8,  # RÃ©sultats par mot-clÃ©
                    include_metadata=True,
                    filter={"session_id": {"$eq": session_id}}
                )
                
                for match in results['matches']:
                    chunk_id = match['id']
                    
                    # Ã‰viter de traiter le mÃªme chunk plusieurs fois
                    if chunk_id in processed_chunks:
                        continue
                    
                    processed_chunks.add(chunk_id)
                    
                    # Extraire les objectifs de ce chunk
                    chunk_text = match['metadata']['text']
                    source_doc = match['metadata']['source']
                    
                    objectives = self._extract_objectives_from_chunk(
                        chunk_text, 
                        source_doc,
                        match['score']
                    )
                    
                    all_objectives.extend(objectives)
                    
            except Exception as e:
                print(f"âš ï¸ Erreur recherche '{keyword}': {e}")
                continue
        
        print(f"ğŸ“Š {len(processed_chunks)} chunks analysÃ©s, {len(all_objectives)} objectifs bruts trouvÃ©s")
        
        # Nettoyer et dÃ©dupliquer les objectifs
        unique_objectives = self._deduplicate_objectives(all_objectives)
        print(f"ğŸ¯ {len(unique_objectives)} objectifs uniques identifiÃ©s")
        
        return unique_objectives
    
    def _extract_objectives_from_chunk(self, text: str, source_doc: str, relevance_score: float) -> List[Dict]:
        """Extrait les objectifs d'un chunk de texte avec gestion d'erreur robuste"""
        try:
            # VÃ©rifier la longueur du texte
            if len(text.strip()) < 20:
                return []
            
            # Utiliser le LLM pour extraire les objectifs
            chain = self.objective_extraction_prompt | self.llm
            result = chain.invoke({"text": text})
            response = result.content
            
            # Parser la rÃ©ponse
            objectives = []
            
            if "AUCUN OBJECTIF IDENTIFIÃ‰" in response:
                return objectives
            
            # Pattern pour extraire les objectifs structurÃ©s
            pattern = r"OBJECTIF:\s*(.*?)\nTYPE:\s*(.*?)\nSOURCE:\s*(.*?)\nCONTEXTE:\s*(.*?)(?=\nOBJECTIF:|$)"
            matches = re.findall(pattern, response, re.DOTALL)
            
            for obj_text, obj_type, obj_source, obj_context in matches:
                # Nettoyer les donnÃ©es extraites
                clean_objective = obj_text.strip()
                clean_type = obj_type.strip().lower()
                clean_source = obj_source.strip()
                clean_context = obj_context.strip()
                
                # Valider que l'objectif est valide
                if len(clean_objective) < 10:  # Trop court
                    continue
                
                objective = {
                    "objective": clean_objective,
                    "type": clean_type,
                    "source_text": clean_source,
                    "context": clean_context,
                    "document_source": source_doc,      # ClÃ© principale
                    "source_document": source_doc,      # ClÃ© alternative
                    "source": source_doc,               # ClÃ© de fallback
                    "relevance_score": float(relevance_score),
                    "extraction_method": "document_analysis",
                    "chunk_text": text[:200] + "..." if len(text) > 200 else text
                }
                objectives.append(objective)
            
            return objectives
            
        except Exception as e:
            print(f"âš ï¸ Erreur extraction objectifs: {e}")
            return []
    
    def _deduplicate_objectives(self, objectives: List[Dict]) -> List[Dict]:
        """Supprime les objectifs en double basÃ©s sur leur similitude"""
        if not objectives:
            return []
        
        unique_objectives = {}
        
        for obj in objectives:
            try:
                # Utiliser les premiers mots de l'objectif comme clÃ© pour la dÃ©duplication
                objective_text = obj.get("objective", "")
                if len(objective_text) < 10:
                    continue
                    
                # CrÃ©er une clÃ© basÃ©e sur les mots significatifs
                words = objective_text.lower().split()
                significant_words = [w for w in words if len(w) > 3][:8]  # 8 premiers mots significatifs
                key_words = " ".join(significant_words)
                
                # Si cet objectif (ou un trÃ¨s similaire) n'existe pas encore
                if key_words not in unique_objectives:
                    unique_objectives[key_words] = obj
                else:
                    # Garder celui avec le meilleur score de pertinence
                    current_score = obj.get("relevance_score", 0.0)
                    existing_score = unique_objectives[key_words].get("relevance_score", 0.0)
                    
                    if current_score > existing_score:
                        unique_objectives[key_words] = obj
                        
            except Exception as e:
                print(f"âš ï¸ Erreur dÃ©duplication: {e}")
                continue
        
        return list(unique_objectives.values())
    
    def get_all_document_content(self, session_id: str) -> List[Dict]:
        """RÃ©cupÃ¨re tout le contenu des documents d'une session"""
        try:
            # Utiliser une requÃªte large pour rÃ©cupÃ©rer tous les chunks
            dummy_embedding = self.embeddings.embed_query("contenu document")
            
            results = self.index.query(
                vector=dummy_embedding,
                top_k=1000,  # RÃ©cupÃ©rer beaucoup de chunks
                include_metadata=True,
                filter={"session_id": {"$eq": session_id}}
            )
            
            # Organiser par document source
            documents_content = {}
            for match in results['matches']:
                source = match['metadata']['source']
                if source not in documents_content:
                    documents_content[source] = []
                
                documents_content[source].append({
                    "text": match['metadata']['text'],
                    "chunk": match['metadata']['chunk'],
                    "score": match['score']
                })
            
            # Reconstituer le texte complet de chaque document
            full_documents = []
            for source, chunks in documents_content.items():
                # Trier par numÃ©ro de chunk
                sorted_chunks = sorted(chunks, key=lambda x: x['chunk'])
                full_text = "\n".join([chunk['text'] for chunk in sorted_chunks])
                
                full_documents.append({
                    "source": source,
                    "full_text": full_text,
                    "num_chunks": len(chunks)
                })
            
            return full_documents
            
        except Exception as e:
            print(f"âŒ Erreur rÃ©cupÃ©ration contenu: {e}")
            return []
    
    def clear_session_data(self, session_id: str):
        """Supprime tous les documents associÃ©s Ã  une session"""
        try:
            self.index.delete(filter={"session_id": {"$eq": session_id}})
            print(f"ğŸ—‘ï¸ DonnÃ©es de session {session_id[:8]} supprimÃ©es")
        except Exception as e:
            print(f"âŒ Erreur suppression: {e}")

class EnhancedLearningObjectiveAgent:
    """Agent principal qui coordonne l'analyse des objectifs avec la gestion de documents"""
    
    def __init__(self, api_key=None, model=None, temperature=None, verbose=None):
        # Configuration de l'API key
        if api_key:
            os.environ["OPENAI_API_KEY"] = api_key
        elif OPENAI_API_KEY:
            os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
        else:
            raise ValueError("ClÃ© API OpenAI requise")
            
        # ParamÃ¨tres du modÃ¨le
        self.model = model or LLM_MODEL
        self.temperature = temperature if temperature is not None else AGENT_TEMPERATURE
        self.verbose = verbose if verbose is not None else VERBOSE_MODE
        
        # Initialisation du modÃ¨le LLM
        self.llm = ChatOpenAI(temperature=self.temperature, model=self.model)
            
        # Initialisation des composants d'analyse
        self.extractor = ObjectiveExtractor(self.llm)
        self.analyzer = ContentAnalyzer(self.llm)
        self.classifier = BloomClassifier(self.llm)
        self.formatter = ObjectiveFormatter(self.llm)
        self.evaluator = DifficultyEvaluator(self.llm)
        self.recommender = LearningResourceRecommender(self.llm)
        self.feedback_generator = FeedbackGenerator(self.llm)
        
        # Processeur de documents
        self.doc_processor = DocumentProcessor()
        
        # Session tracking
        self.current_session_id = None
        self.processed_documents = []
        self.extracted_document_objectives = []  # Objectifs extraits des documents
        
        # CrÃ©ation des outils avec gestion de documents
        self.tools = [
            Tool(
                name="extract_objectives",
                func=self.extract_objectives,
                description="Extrait les objectifs d'apprentissage d'un texte"
            ),
            Tool(
                name="analyze_content",
                func=self.analyze_content,
                description="Analyse le contenu pÃ©dagogique"
            ),
            Tool(
                name="classify_objectives",
                func=self.classify_objectives,
                description="Classifie les objectifs selon la taxonomie de Bloom"
            ),
            Tool(
                name="format_objectives",
                func=self.format_objectives,
                description="Reformule et amÃ©liore les objectifs d'apprentissage"
            ),
            Tool(
                name="evaluate_difficulty",
                func=self.evaluate_difficulty,
                description="Ã‰value la difficultÃ© des objectifs d'apprentissage"
            ),
            Tool(
                name="recommend_resources",
                func=self.recommend_resources,
                description="Recommande des ressources d'apprentissage"
            ),
            Tool(
                name="generate_feedback",
                func=self.generate_feedback,
                description="GÃ©nÃ¨re du feedback sur les objectifs d'apprentissage"
            ),
            Tool(
                name="search_documents",
                func=self.search_documents,
                description="Recherche des informations dans les documents uploadÃ©s"
            ),
            Tool(
                name="extract_document_objectives",
                func=self.extract_document_objectives,
                description="Extrait les objectifs d'apprentissage depuis les documents stockÃ©s"
            )
        ]
        
        # CrÃ©ation du prompt de l'agent
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """Vous Ãªtes un agent d'intelligence artificielle spÃ©cialisÃ© dans l'analyse et l'amÃ©lioration des objectifs d'apprentissage selon la taxonomie de Bloom. 

Vous avez accÃ¨s aux outils suivants pour vous aider dans votre analyse:
- extract_objectives: Pour extraire les objectifs d'apprentissage d'un texte
- analyze_content: Pour analyser le contenu pÃ©dagogique
- classify_objectives: Pour classifier selon la taxonomie de Bloom
- format_objectives: Pour reformuler les objectifs
- evaluate_difficulty: Pour Ã©valuer la difficultÃ©
- recommend_resources: Pour recommander des ressources
- generate_feedback: Pour gÃ©nÃ©rer du feedback
- search_documents: Pour rechercher dans les documents uploadÃ©s
- extract_document_objectives: Pour extraire les objectifs depuis les documents stockÃ©s

IMPORTANT: Quand des documents ont Ã©tÃ© uploadÃ©s, utilisez TOUJOURS l'outil extract_document_objectives pour identifier les objectifs d'apprentissage qui se trouvent dÃ©jÃ  dans ces documents.

Pour chaque demande, suivez ces Ã©tapes:
1. Si des documents sont disponibles, extrayez d'abord les objectifs qu'ils contiennent
2. Recherchez des informations pertinentes supplÃ©mentaires dans les documents
3. Extrayez et analysez les objectifs d'apprentissage du contenu fourni
4. Combinez tous les objectifs trouvÃ©s (documents + contenu)
5. Classifiez-les selon la taxonomie de Bloom
6. Reformulez-les pour les amÃ©liorer
7. Ã‰valuez leur difficultÃ©
8. Recommandez des ressources appropriÃ©es
9. GÃ©nÃ©rez un feedback constructif

Utilisez une approche Ã©tape par Ã©tape et expliquez clairement votre raisonnement.
            """),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad")
        ])
        
        # CrÃ©ation de l'agent avec OpenAI Tools
        self.agent = create_openai_tools_agent(self.llm, self.tools, self.prompt)
        self.agent_executor = AgentExecutor(
            agent=self.agent, 
            tools=self.tools, 
            verbose=self.verbose,
            max_iterations=5,
            handle_parsing_errors=True
        )
        
        print("âœ… Agent d'objectifs d'apprentissage initialisÃ© avec succÃ¨s")
    
    def process_uploaded_files(self, files: List, session_id: str = None) -> str:
        """
        Traite les fichiers uploadÃ©s et les stocke pour utilisation ultÃ©rieure
        
        Args:
            files: Liste des fichiers uploadÃ©s
            session_id: Identifiant de session (gÃ©nÃ©rÃ© automatiquement si non fourni)
            
        Returns:
            RÃ©sumÃ© du traitement
        """
        if not session_id:
            import uuid
            session_id = str(uuid.uuid4())
        
        self.current_session_id = session_id
        
        try:
            print(f"ğŸš€ DÃ©but du traitement - Session: {session_id[:8]}")
            
            document_texts, document_names = self.doc_processor.process_documents(files, session_id)
            
            self.processed_documents = []
            for i, (text, name) in enumerate(zip(document_texts, document_names)):
                self.processed_documents.append({
                    "name": name,
                    "text_preview": text[:200] + "..." if len(text) > 200 else text,
                    "full_text": text,
                    "word_count": len(text.split()),
                    "char_count": len(text)
                })
            
            # Extraire automatiquement les objectifs des documents uploadÃ©s
            print("ğŸ” Extraction des objectifs depuis les documents...")
            self.extracted_document_objectives = self.doc_processor.extract_objectives_from_stored_documents(session_id)
            
            result_message = f"âœ… {len(files)} fichier(s) traitÃ©(s) avec succÃ¨s."
            if self.extracted_document_objectives:
                result_message += f" {len(self.extracted_document_objectives)} objectif(s) d'apprentissage identifiÃ©(s) dans les documents."
            else:
                result_message += " Aucun objectif explicite trouvÃ©, mais le contenu enrichira l'analyse."
            
            print(f"ğŸ‰ {result_message}")
            return result_message
            
        except Exception as e:
            error_msg = f"âŒ Erreur lors du traitement des fichiers: {str(e)}"
            print(error_msg)
            return error_msg
    
    def extract_document_objectives(self, query: str = "") -> str:
        """Extrait les objectifs d'apprentissage depuis les documents stockÃ©s"""
        if not self.current_session_id:
            return "Aucun document n'a Ã©tÃ© uploadÃ© pour cette session."
        
        if not hasattr(self, 'extracted_document_objectives') or not self.extracted_document_objectives:
            # Extraire les objectifs si pas encore fait
            print("ğŸ”„ Extraction des objectifs en cours...")
            self.extracted_document_objectives = self.doc_processor.extract_objectives_from_stored_documents(
                self.current_session_id
            )
        
        if not self.extracted_document_objectives:
            return "Aucun objectif d'apprentissage n'a Ã©tÃ© trouvÃ© dans les documents uploadÃ©s."
        
        # Formater les objectifs pour l'affichage
        result = f"ğŸ“‹ Objectifs d'apprentissage extraits des documents ({len(self.extracted_document_objectives)}):\n\n"
        
        for i, obj in enumerate(self.extracted_document_objectives, 1):
            source_doc = obj.get('document_source', obj.get('source_document', obj.get('source', 'Document inconnu')))
            obj_type = obj.get('type', 'non classifiÃ©')
            source_text = obj.get('source_text', 'Texte source non disponible')
            
            result += f"{i}. {obj['objective']}\n"
            result += f"   Type: {obj_type}\n"
            result += f"   Source: {source_doc}\n"
            result += f"   Extrait de: \"{source_text[:100]}...\"\n\n"
        
        return result
    
    def search_documents(self, query: str) -> str:
        """Recherche des informations dans les documents uploadÃ©s"""
        if not self.current_session_id:
            return "Aucun document n'a Ã©tÃ© uploadÃ© pour cette session."
        
        relevant_content = self.doc_processor.search_relevant_content(
            query, self.current_session_id, top_k=5
        )
        
        if not relevant_content:
            return "Aucun contenu pertinent trouvÃ© dans les documents uploadÃ©s."
        
        return "\n\n---\n\n".join(relevant_content)
    
    def extract_objectives(self, text: str) -> str:
        """Extrait les objectifs d'apprentissage d'un texte"""
        try:
            result = self.extractor.extract(text)
            return "\n".join(result)
        except Exception as e:
            print(f"âš ï¸ Erreur extraction objectifs: {e}")
            return "Erreur lors de l'extraction des objectifs"
    
    def analyze_content(self, content: str) -> str:
        """Analyse le contenu pÃ©dagogique"""
        try:
            result = self.analyzer.analyze(content)
            return result["analysis"]
        except Exception as e:
            print(f"âš ï¸ Erreur analyse contenu: {e}")
            return "Erreur lors de l'analyse du contenu"
    
    def classify_objectives(self, objectives: str) -> str:
        """Classifie les objectifs selon la taxonomie de Bloom"""
        try:
            objectives_list = [obj.strip() for obj in objectives.split("\n") if obj.strip()]
            result = self.classifier.classify(objectives_list)
            return result["classification"]
        except Exception as e:
            print(f"âš ï¸ Erreur classification: {e}")
            return "Erreur lors de la classification"
    
    def format_objectives(self, objectives: str) -> str:
        """Reformule et amÃ©liore les objectifs d'apprentissage"""
        try:
            objectives_list = [obj.strip() for obj in objectives.split("\n") if obj.strip()]
            result = self.formatter.format(objectives_list)
            return result["formatted_objectives"]
        except Exception as e:
            print(f"âš ï¸ Erreur formatage: {e}")
            return "Erreur lors de la reformulation"
    
    def evaluate_difficulty(self, objectives: str) -> str:
        """Ã‰value la difficultÃ© des objectifs d'apprentissage"""
        try:
            objectives_list = [obj.strip() for obj in objectives.split("\n") if obj.strip()]
            result = self.evaluator.evaluate(objectives_list)
            return result["difficulty_evaluation"]
        except Exception as e:
            print(f"âš ï¸ Erreur Ã©valuation difficultÃ©: {e}")
            return "Erreur lors de l'Ã©valuation de difficultÃ©"
    
    def recommend_resources(self, objectives_with_levels: str) -> str:
        """Recommande des ressources d'apprentissage"""
        try:
            objectives_list = []
            bloom_levels = {}
            
            pattern = r"Objectif: (.*?)\nNiveau Bloom: (.*?)(?:\n|$)"
            matches = re.findall(pattern, objectives_with_levels, re.DOTALL)
            
            for obj, level in matches:
                objectives_list.append(obj.strip())
                bloom_levels[obj.strip()] = level.strip()
            
            result = self.recommender.recommend(objectives_list, bloom_levels)
            return result["recommendations"]
        except Exception as e:
            print(f"âš ï¸ Erreur recommandations: {e}")
            return "Erreur lors des recommandations"
    
    def generate_feedback(self, objectives_with_classifications: str) -> str:
        """GÃ©nÃ¨re du feedback sur les objectifs d'apprentissage"""
        try:
            objectives_list = []
            classifications = {}
            
            pattern = r"Objectif: (.*?)\n(.*?)(?=\nObjectif:|$)"
            matches = re.findall(pattern, objectives_with_classifications, re.DOTALL)
            
            for obj, classification in matches:
                obj = obj.strip()
                objectives_list.append(obj)
                classifications[obj] = classification.strip()
            
            result = self.feedback_generator.generate_feedback(objectives_list, classifications)
            return result["feedback"]
        except Exception as e:
            print(f"âš ï¸ Erreur feedback: {e}")
            return "Erreur lors de la gÃ©nÃ©ration du feedback"
    
    def process_content_with_documents(self, content: str) -> Dict:
        """
        Traite le contenu pÃ©dagogique en enrichissant avec les documents uploadÃ©s
        
        Args:
            content: Le contenu pÃ©dagogique Ã  analyser
            
        Returns:
            Les rÃ©sultats de l'analyse enrichie
        """
        print("ğŸš€ DÃ©but de l'analyse complÃ¨te...")
        
        # Enrichir le contenu avec les informations des documents uploadÃ©s
        enriched_content = content
        
        if self.current_session_id and self.processed_documents:
            print("ğŸ“„ Enrichissement avec les documents...")
            
            # Rechercher du contenu pertinent sur les objectifs d'apprentissage
            relevant_content = self.doc_processor.search_relevant_content(
                "objectifs d'apprentissage compÃ©tences", 
                self.current_session_id, 
                top_k=3
            )
            
            if relevant_content:
                enriched_content += "\n\n## Contenu extrait des documents uploadÃ©s:\n\n"
                enriched_content += "\n\n".join(relevant_content)
            
            # Ajouter les objectifs extraits des documents
            if hasattr(self, 'extracted_document_objectives') and self.extracted_document_objectives:
                enriched_content += "\n\n## Objectifs d'apprentissage trouvÃ©s dans les documents uploadÃ©s:\n\n"
                for obj in self.extracted_document_objectives:
                    source_doc = obj.get('document_source', obj.get('source_document', obj.get('source', 'Document inconnu')))
                    obj_type = obj.get('type', 'non classifiÃ©')
                    enriched_content += f"- {obj['objective']} (Source: {source_doc}, Type: {obj_type})\n"
        
        # Traitement direct pour obtenir les rÃ©sultats structurÃ©s
        try:
            print("ğŸ¯ Extraction des objectifs du contenu...")
            # Extraire les objectifs du contenu fourni
            content_objectives = self.extractor.extract(enriched_content)
            
            # Combiner avec les objectifs extraits des documents
            all_objectives = content_objectives.copy()
            document_objectives_info = []
            
            if hasattr(self, 'extracted_document_objectives') and self.extracted_document_objectives:
                print(f"ğŸ“„ IntÃ©gration de {len(self.extracted_document_objectives)} objectifs des documents...")
                
                for doc_obj in self.extracted_document_objectives:
                    # Ajouter Ã  la liste globale
                    all_objectives.append(doc_obj['objective'])
                    
                    # PrÃ©parer les informations dÃ©taillÃ©es
                    source_doc = doc_obj.get('document_source', doc_obj.get('source_document', doc_obj.get('source', 'Document inconnu')))
                    
                    document_objectives_info.append({
                        "objective": doc_obj.get('objective', 'Objectif non spÃ©cifiÃ©'),
                        "type": doc_obj.get('type', 'non classifiÃ©'),
                        "source_document": source_doc,
                        "document_source": source_doc,  # ClÃ© alternative
                        "source": source_doc,           # ClÃ© de fallback
                        "source_text": doc_obj.get('source_text', 'Texte non disponible'),
                        "relevance_score": doc_obj.get('relevance_score', 0.0),
                        "context": doc_obj.get('context', 'Contexte non disponible')
                    })
            
            print(f"ğŸ“Š Total: {len(all_objectives)} objectifs Ã  analyser")
            
            # Analyser le contenu enrichi
            print("ğŸ” Analyse du contenu...")
            content_analysis = self.analyzer.analyze(enriched_content)
            
            # Classifier tous les objectifs
            print("ğŸ·ï¸ Classification selon Bloom...")
            classification_result = self.classifier.classify(all_objectives)
            
            print("âœ¨ Reformulation des objectifs...")
            formatted_objectives = self.formatter.format(all_objectives)
            
            print("âš–ï¸ Ã‰valuation de la difficultÃ©...")
            difficulty_evaluation = self.evaluator.evaluate(all_objectives)
            
            # Extraction des niveaux de Bloom
            print("ğŸŒ¸ Extraction des niveaux de Bloom...")
            bloom_levels = {}
            for obj in all_objectives:
                pattern = re.compile(rf"{re.escape(obj)}.*?Niveau de Bloom: ([a-zÃ©Ã¨ ]+)", re.DOTALL | re.IGNORECASE)
                match = pattern.search(classification_result["classification"])
                if match:
                    bloom_levels[obj] = match.group(1).strip()
                else:
                    bloom_levels[obj] = "non classifiÃ©"
            
            print("ğŸ“š GÃ©nÃ©ration des recommandations...")
            recommendations = self.recommender.recommend(all_objectives, bloom_levels)
            
            # Extraction des classifications pour le feedback
            classifications = {}
            pattern = r"Objectif: (.*?)\n(.*?)(?=Objectif:|$)"
            matches = re.findall(pattern, classification_result["classification"], re.DOTALL)
            for obj, classification in matches:
                obj = obj.strip()
                classifications[obj] = classification.strip()
            
            print("ğŸ’¡ GÃ©nÃ©ration du feedback...")
            feedback = self.feedback_generator.generate_feedback(all_objectives, classifications)
            
            # Compilation des rÃ©sultats
            results = {
                "objectives": all_objectives,
                "content_objectives": content_objectives,
                "document_objectives": document_objectives_info,
                "content_analysis": content_analysis,
                "classification": classification_result,
                "formatted_objectives": formatted_objectives,
                "difficulty_evaluation": difficulty_evaluation,
                "recommendations": recommendations,
                "feedback": feedback,
                "stats": {
                    "total_objectives": len(all_objectives),
                    "content_objectives_count": len(content_objectives),
                    "document_objectives_count": len(document_objectives_info),
                    "processed_documents": len(self.processed_documents) if self.processed_documents else 0,
                    "session_id": self.current_session_id
                }
            }
            
            print("âœ… Analyse terminÃ©e avec succÃ¨s!")
            return results
            
        except Exception as e:
            error_msg = f"âŒ Erreur lors de l'analyse: {str(e)}"
            print(error_msg)
            
            return {
                "error": str(e),
                "objectives": [],
                "content_objectives": [],
                "document_objectives": [],
                "content_analysis": {"analysis": "Erreur lors de l'analyse"},
                "classification": {"classification": "Erreur lors de la classification"},
                "formatted_objectives": {"formatted_objectives": "Erreur lors de la reformulation"},
                "difficulty_evaluation": {"difficulty_evaluation": "Erreur lors de l'Ã©valuation"},
                "recommendations": {"recommendations": "Erreur lors des recommandations"},
                "feedback": {"feedback": "Erreur lors de la gÃ©nÃ©ration du feedback"},
                "stats": {
                    "total_objectives": 0,
                    "content_objectives_count": 0,
                    "document_objectives_count": 0,
                    "processed_documents": 0,
                    "session_id": self.current_session_id
                }
            }
    
    def get_processed_documents_summary(self) -> List[Dict]:
        """Retourne un rÃ©sumÃ© des documents traitÃ©s"""
        return self.processed_documents
    
    def get_extracted_document_objectives(self) -> List[Dict]:
        """Retourne les objectifs extraits des documents"""
        if hasattr(self, 'extracted_document_objectives'):
            return self.extracted_document_objectives
        return []
    
    def get_session_statistics(self) -> Dict:
        """Retourne les statistiques de la session"""
        return {
            "session_id": self.current_session_id,
            "processed_documents_count": len(self.processed_documents),
            "extracted_objectives_count": len(self.extracted_document_objectives) if hasattr(self, 'extracted_document_objectives') else 0,
            "total_words": sum([doc.get('word_count', 0) for doc in self.processed_documents]),
            "total_chars": sum([doc.get('char_count', 0) for doc in self.processed_documents])
        }
    
    def clear_session(self):
        """Efface les donnÃ©es de la session actuelle"""
        if self.current_session_id:
            print(f"ğŸ—‘ï¸ Nettoyage de la session {self.current_session_id[:8]}...")
            self.doc_processor.clear_session_data(self.current_session_id)
            self.current_session_id = None
            self.processed_documents = []
            self.extracted_document_objectives = []
            print("âœ… Session nettoyÃ©e")
    
    def run(self, input_text: str) -> Dict:
        """ExÃ©cute l'agent avec le texte d'entrÃ©e"""
        try:
            result = self.agent_executor.invoke({"input": input_text})
            return result
        except Exception as e:
            print(f"âŒ Erreur agent: {e}")
            return {"output": f"Erreur lors de l'exÃ©cution de l'agent: {str(e)}"}

# Fonction d'aide pour l'utilisation
def create_enhanced_agent(api_key=None, model=None):
    """Fonction d'aide pour crÃ©er un agent amÃ©liorÃ©"""
    try:
        return EnhancedLearningObjectiveAgent(
            api_key=api_key,
            model=model
        )
    except Exception as e:
        print(f"âŒ Erreur crÃ©ation agent: {e}")
        raise

# Exemple d'utilisation et tests
if __name__ == "__main__":
    print("ğŸ§ª Test de l'agent d'objectifs d'apprentissage")
    
    try:
        # CrÃ©er l'agent
        agent = create_enhanced_agent()
        
        # Test avec du contenu simple
        content = """
        Ce cours vise Ã  enseigner les bases de l'intelligence artificielle.
        Ã€ la fin de ce cours, les Ã©tudiants seront capables de:
        - Comprendre les concepts fondamentaux de l'IA
        - ImplÃ©menter des algorithmes d'apprentissage automatique simples
        - Analyser les performances des modÃ¨les
        """
        
        print("ğŸ“ Test d'analyse de contenu...")
        results = agent.process_content_with_documents(content)
        
        print("\n=== RÃ‰SULTATS DE TEST ===")
        print(f"âœ… Objectifs trouvÃ©s: {results['stats']['total_objectives']}")
        print(f"ğŸ“Š Contenu: {results['stats']['content_objectives_count']}")
        print(f"ğŸ“„ Documents: {results['stats']['document_objectives_count']}")
        
        if results.get("error"):
            print(f"âŒ Erreur: {results['error']}")
        else:
            print("âœ… Test rÃ©ussi!")
            
    except Exception as e:
        print(f"âŒ Erreur durant le test: {e}")
    
    print("ğŸ‰ Fin des tests")